"""
Habermetre - Haber Gruplama (Clustering) ModÃ¼lÃ¼

BERT embeddings kullanarak TÃ¼rkÃ§e haberleri anlamsal olarak gruplar.
"""

from sentence_transformers import SentenceTransformer
from sklearn.cluster import DBSCAN
from collections import Counter
import numpy as np
import re


class NewsClusterer:
    """Haber gruplama sÄ±nÄ±fÄ±"""
    
    def __init__(self, model_name='paraphrase-multilingual-MiniLM-L12-v2'):
        """
        Args:
            model_name: Sentence transformer model adÄ±
        """
        print(f"ğŸ“¥ BERT modeli yÃ¼kleniyor: {model_name}")
        self.model = SentenceTransformer(model_name)
        print(f"âœ… Model yÃ¼klendi ({self.model.get_sentence_embedding_dimension()} boyutlu vektÃ¶rler)")
    
    def extract_keywords(self, text, top_n=3):
        """
        Metinden anahtar kelimeleri Ã§Ä±kar
        
        Args:
            text: Metin
            top_n: KaÃ§ kelime
            
        Returns:
            En sÄ±k kullanÄ±lan kelimeler
        """
        # TÃ¼rkÃ§e stopwords (durdurulmasÄ± gereken kelimeler)
        stopwords = {
            've', 'veya', 'ile', 'ama', 'fakat', 'ancak', 'iÃ§in', 'gibi', 
            'bir', 'bu', 'ÅŸu', 'o', 'ne', 'nasÄ±l', 'neden', 'niÃ§in',
            'mi', 'mÄ±', 'mu', 'mÃ¼', 'de', 'da', 'ki', 'dÄ±', 'di',
            'var', 'yok', 'olan', 'oldu', 'olacak', 'etti', 'ediyor',
            'den', 'dan', 'ten', 'tan', 'e', 'a', 'ye', 'ya'
        }
        
        # KÃ¼Ã§Ã¼k harfe Ã§evir ve sadece harfleri al
        words = re.findall(r'\b\w+\b', text.lower())
        
        # Stopwords ve kÄ±sa kelimeleri filtrele
        filtered = [w for w in words if w not in stopwords and len(w) > 2]
        
        # En sÄ±k kullanÄ±lanlarÄ± bul
        if not filtered:
            return []
        
        counter = Counter(filtered)
        return [word for word, _ in counter.most_common(top_n)]
    
    def generate_cluster_title(self, news_items):
        """
        KÃ¼me iÃ§in otomatik baÅŸlÄ±k oluÅŸtur
        
        Args:
            news_items: KÃ¼medeki haberler
            
        Returns:
            KÃ¼me baÅŸlÄ±ÄŸÄ±
        """
        # TÃ¼m baÅŸlÄ±klarÄ± birleÅŸtir
        all_text = ' '.join([item['title'] for item in news_items])
        
        # En sÄ±k kullanÄ±lan 2-3 kelimeyi al
        keywords = self.extract_keywords(all_text, top_n=3)
        
        if keywords:
            return ' '.join(keywords).title()
        else:
            return news_items[0]['title'][:50] + '...'
    
    def cluster_news(self, news_items, eps=0.35, min_samples=2):
        """
        Haberleri kÃ¼melere ayÄ±r
        
        Args:
            news_items: Haber listesi (dict'ler)
            eps: DBSCAN epsilon parametresi (0-1, dÃ¼ÅŸÃ¼k = sÄ±kÄ± gruplama)
            min_samples: Minimum haber sayÄ±sÄ±
            
        Returns:
            {
                cluster_id: {
                    'title': 'KÃ¼me BaÅŸlÄ±ÄŸÄ±',
                    'count': 5,
                    'news': [...]
                }
            }
        """
        if not news_items:
            return {}
        
        # BaÅŸlÄ±klarÄ± al
        titles = [item['title'] for item in news_items]
        
        print(f"ğŸ” {len(titles)} haber iÃ§in embedding hesaplanÄ±yor...")
        
        # Embedding'lere Ã§evir
        embeddings = self.model.encode(titles, show_progress_bar=False)
        
        print(f"ğŸ“Š Clustering yapÄ±lÄ±yor (eps={eps}, min_samples={min_samples})...")
        
        # DBSCAN clustering (cosine distance kullan)
        clustering = DBSCAN(eps=eps, min_samples=min_samples, metric='cosine')
        labels = clustering.fit_predict(embeddings)
        
        # KÃ¼meleri oluÅŸtur
        clusters = {}
        for idx, label in enumerate(labels):
            # -1 = noise (kÃ¼meye girmeyen)
            if label == -1:
                # Tek baÅŸÄ±na haberler iÃ§in ayrÄ± kÃ¼meler oluÅŸtur
                label = f"single_{idx}"
            
            if label not in clusters:
                clusters[label] = []
            
            clusters[label].append(news_items[idx])
        
        print(f"âœ… {len(clusters)} kÃ¼me oluÅŸturuldu")
        
        # Her kÃ¼me iÃ§in baÅŸlÄ±k oluÅŸtur
        result = {}
        for cluster_id, items in clusters.items():
            result[cluster_id] = {
                'id': cluster_id,
                'title': self.generate_cluster_title(items),
                'count': len(items),
                'news': sorted(items, key=lambda x: x.get('pub_date') or '', reverse=True)
            }
        
        # KÃ¼meleri haber sayÄ±sÄ±na gÃ¶re sÄ±rala
        sorted_clusters = dict(sorted(
            result.items(), 
            key=lambda x: x[1]['count'], 
            reverse=True
        ))
        
        return sorted_clusters


# Global singleton
_clusterer = None

def get_clusterer():
    """Global clusterer instance"""
    global _clusterer
    if _clusterer is None:
        _clusterer = NewsClusterer()
    return _clusterer
