"""
Habermetre - Haber Gruplama (Clustering) ModÃ¼lÃ¼

BERT embeddings kullanarak TÃ¼rkÃ§e haberleri anlamsal olarak gruplar.
"""


from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.cluster import DBSCAN
from collections import Counter
import re
import numpy as np

class NewsClusterer:
    """Haber gruplama sÄ±nÄ±fÄ± (TF-IDF Lightweight SÃ¼rÃ¼mÃ¼)"""
    
    def __init__(self, model_name=None):
        """
        Args:
            model_name: Geriye uyumluluk iÃ§in tutuldu (kullanÄ±lmÄ±yor)
        """
        print("ğŸ“¥ TF-IDF VektÃ¶rleÅŸtirici ile baÅŸlatÄ±lÄ±yor (Lightweight Mode)")
        self.vectorizer = TfidfVectorizer(
            stop_words=None, # TÃ¼rkÃ§e stop words aÅŸaÄŸÄ±da manuel temizleniyor
            max_features=5000,
            ngram_range=(1, 2)
        )
    
    def extract_keywords(self, text, top_n=3):
        """Metinden anahtar kelimeleri Ã§Ä±kar"""
        stopwords = {
            've', 'veya', 'ile', 'ama', 'fakat', 'ancak', 'iÃ§in', 'gibi', 
            'bir', 'bu', 'ÅŸu', 'o', 'ne', 'nasÄ±l', 'neden', 'niÃ§in',
            'mi', 'mÄ±', 'mu', 'mÃ¼', 'de', 'da', 'ki', 'dÄ±', 'di',
            'var', 'yok', 'olan', 'oldu', 'olacak', 'etti', 'ediyor',
            'den', 'dan', 'ten', 'tan', 'e', 'a', 'ye', 'ya', 'ile'
        }
        
        words = re.findall(r'\b\w+\b', text.lower())
        filtered = [w for w in words if w not in stopwords and len(w) > 2]
        
        if not filtered:
            return []
        
        counter = Counter(filtered)
        return [word for word, _ in counter.most_common(top_n)]
    
    def generate_cluster_title(self, news_items):
        """KÃ¼me iÃ§in otomatik baÅŸlÄ±k oluÅŸtur"""
        all_text = ' '.join([item['title'] for item in news_items])
        keywords = self.extract_keywords(all_text, top_n=3)
        
        if keywords:
            return ' '.join(keywords).title()
        else:
            return news_items[0]['title'][:50] + '...'
    
    def cluster_news(self, news_items, eps=0.4, min_samples=2):
        """Haberleri kÃ¼melere ayÄ±r (TF-IDF + DBSCAN)"""
        if not news_items:
            return {}
        
        titles = [item['title'] for item in news_items]
        
        print(f"ğŸ” {len(titles)} haber iÃ§in TF-IDF hesaplanÄ±yor...")
        
        # TF-IDF Matrisi oluÅŸtur
        try:
            tfidf_matrix = self.vectorizer.fit_transform(titles)
            
            # DBSCAN (Cosine Similarity = 1 - Cosine Distance)
            # sklearn DBSCAN varsayÄ±lan olarak euclidean kullanÄ±r. 
            # TF-IDF l2 normalize olduÄŸu iÃ§in euclidean ~ cosine distance davranÄ±r.
            # Ancak biz yine de 'cosine' metriÄŸini kullanalÄ±m daha doÄŸru sonuÃ§ iÃ§in.
            
            print(f"ğŸ“Š Clustering yapÄ±lÄ±yor (eps={eps}, min_samples={min_samples})...")
            
            clustering = DBSCAN(eps=eps, min_samples=min_samples, metric='cosine', algorithm='brute')
            labels = clustering.fit_predict(tfidf_matrix) # Sparse matrix destekler
            
            # KÃ¼meleri oluÅŸtur
            clusters = {}
            for idx, label in enumerate(labels):
                if label == -1: # Noise
                    label = f"single_{idx}"
                else:
                    label = str(label) # JSON uyumluluÄŸu iÃ§in string
                
                if label not in clusters:
                    clusters[label] = []
                
                clusters[label].append(news_items[idx])
            
            print(f"âœ… {len(clusters)} kÃ¼me oluÅŸturuldu")
            
            # SonuÃ§larÄ± hazÄ±rla
            result = {}
            for cluster_id, items in clusters.items():
                result[cluster_id] = {
                    'id': cluster_id,
                    'title': self.generate_cluster_title(items),
                    'count': len(items),
                    'news': sorted(items, key=lambda x: x.get('pub_date') or '', reverse=True)
                }
            
            # SÄ±rala
            sorted_clusters = dict(sorted(
                result.items(), 
                key=lambda x: x[1]['count'], 
                reverse=True
            ))
            
            return sorted_clusters

        except ValueError:
            # BoÅŸ veri vb. durumlarda
            return {}

# Global singleton
_clusterer = None

def get_clusterer():
    global _clusterer
    if _clusterer is None:
        _clusterer = NewsClusterer()
    return _clusterer

